{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 21:59:28.625980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "from glob import glob\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2, functional\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import image as tf_image\n",
    "from tensorflow import io as tf_io\n",
    "\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Lorenz's libs\n",
    "# import math\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "# from pyproj import Proj, Transformer\n",
    "import random\n",
    "# from tqdm import tqdm\n",
    "# import folium\n",
    "# from folium.plugins import MarkerCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert RGB to the personal LAB (LAB2)\n",
    "# the input R,G,B,  must be 1D from 0 to 255\n",
    "# the outputs are 1D  L [0 1], a [-1 1] b [-1 1]\n",
    "def RGB2LAB2(R0, G0, B0):\n",
    "\n",
    "    R=R0/255\n",
    "    G=G0/255\n",
    "    B=B0/255\n",
    "\n",
    "    # Y=0.3*R + 0.59*G + 0.11*B\n",
    "    # X=0.45*R + 0.35*G + 0.2*B\n",
    "    # Z=0.01*R + 0.09*G + 0.9*B\n",
    "\n",
    "    Y=0.299*R + 0.587*G + 0.114*B\n",
    "    X=0.449*R + 0.353*G + 0.198*B\n",
    "    Z=0.012*R + 0.089*G + 0.899*B\n",
    "\n",
    "    # X - Y = 0.150*R - 0.234*G + 0.084*B  = a0\n",
    "    # Y - Z = 0.287*R + 0.498*G - 0.785*B  = b0\n",
    "\n",
    "    L = Y\n",
    "    a = (X - Y)/0.234\n",
    "    b = (Y - Z)/0.785\n",
    "\n",
    "    return L, a, b\n",
    "\n",
    "## convert the personal LAB (LAB2)to the RGB\n",
    "# the input L,a,b,  must be 1D L [0 1], a [-1 1] b [-1 1]\n",
    "# the outputs are 1D  R g B [0 255]\n",
    "def LAB22RGB(L, a, b):\n",
    "\n",
    "    a11 = 0.299\n",
    "    a12 = 0.587\n",
    "    a13 = 0.114\n",
    "    a21 = (0.15/0.234)\n",
    "    a22 = (-0.234/0.234)\n",
    "    a23 = (0.084/0.234)\n",
    "    a31 = (0.287/0.785)\n",
    "    a32 = (0.498/0.785)\n",
    "    a33 = (-0.785/0.785)\n",
    "\n",
    "    aa=np.array([[a11, a12, a13], [a21, a22, a23], [a31, a32, a33]])\n",
    "    C0=np.zeros((L.shape[0],3))\n",
    "    C0[:,0]=L[:,0]\n",
    "    C0[:,1]=a[:,0]\n",
    "    C0[:,2]=b[:,0]\n",
    "    C = np.transpose(C0)\n",
    "    # C = np.array([L, a, b])\n",
    "    # print(C.shape)\n",
    "    # print(L.shape)\n",
    "    # print(a.shape)\n",
    "    # print(b.shape)\n",
    "    # print(aa.shape)\n",
    "\n",
    "    X = np.linalg.inv(aa).dot(C)\n",
    "    X1D=np.reshape(X,(X.shape[0]*X.shape[1],1))\n",
    "    p0=np.where(X1D<0)\n",
    "    X1D[p0[0]]=0\n",
    "    p1=np.where(X1D>1)\n",
    "    X1D[p1[0]]=1\n",
    "    Xr=np.reshape(X1D,(X.shape[0],X.shape[1]))\n",
    "\n",
    "    Rr = Xr[0][:]\n",
    "    Gr = Xr[1][:]\n",
    "    Br = Xr[2][:]\n",
    "\n",
    "    R = np.uint(np.round(Rr*255))\n",
    "    G = np.uint(np.round(Gr*255))\n",
    "    B = np.uint(np.round(Br*255))\n",
    "    # p0=np.where(L<0.02)\n",
    "    # R[p0[0]]=0\n",
    "    # G[p0[0]]=0\n",
    "    # B[p0[0]]=0\n",
    "    # p1=np.where(L>0.98)\n",
    "    # R[p1[0]]=255\n",
    "    # G[p1[0]]=255\n",
    "    # B[p1[0]]=255\n",
    "    return R, G, B\n",
    "\n",
    "\n",
    "\n",
    "def convert_RGB_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB2(R1, G1, B1)\n",
    "\n",
    "    train_input[:, :, 0] = L.reshape((sz_x, sz_y))\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transform(orig_img, imgs, with_orig=True, row_title=None, img_size = 10, **imshow_kwargs):\n",
    "\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False, figsize = (img_size, img_size))\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom Dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SwisstopoDataset:\n",
    "    def __init__(self, img_indx, transform=None, large_dataset=False, return_label=True, batch_size=32):\n",
    "        self.img_indx = img_indx\n",
    "        self.transform = transform\n",
    "        self.large_dataset = large_dataset\n",
    "        self.return_label = return_label\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Set the appropriate port based on the dataset size\n",
    "        self.port = 1986 if self.large_dataset else 1985\n",
    "\n",
    "        # Load metadata\n",
    "        self.metadata_file = self._load_metadata()\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        raw_data_csv_file_link = f\"https://perritos.myasustor.com:{self.port}/metadata.csv\"\n",
    "        return pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "\n",
    "    def _fetch_image(self, img_id):\n",
    "        img_in_server_link = f\"https://perritos.myasustor.com:{self.port}/data/img_id_{img_id}.jpg\"\n",
    "        response = requests.get(img_in_server_link)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "\n",
    "    def _process_image(self, img_id):\n",
    "        image = self._fetch_image(img_id)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            image = image / 255.0  # Default normalization\n",
    "        return image\n",
    "\n",
    "    def _get_label(self, idx):\n",
    "        return self.metadata_file[\"class\"].iloc[idx]\n",
    "\n",
    "    def _generator(self):\n",
    "        for idx in range(len(self.img_indx)):\n",
    "            image = self._process_image(self.img_indx[idx])\n",
    "            L, AB = image  # Unpack the transformed image\n",
    "            if self.return_label:\n",
    "                label = self._get_label(idx)\n",
    "                yield (L, AB), label\n",
    "            else:\n",
    "                yield L, AB\n",
    "\n",
    "    def get_dataset(self):\n",
    "        # Dynamically infer the shapes of L and AB channels\n",
    "        def _dynamic_output_signature():\n",
    "            example_image = self._fetch_image(self.img_indx[0])\n",
    "            example_transformed = self.transform(example_image)\n",
    "            L, AB = example_transformed\n",
    "            L_shape = tf.TensorSpec(shape=L.shape, dtype=tf.float32)\n",
    "            AB_shape = tf.TensorSpec(shape=AB.shape, dtype=tf.float32)\n",
    "            if self.return_label:\n",
    "                return ((L_shape, AB_shape), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
    "            else:\n",
    "                return (L_shape, AB_shape)\n",
    "\n",
    "        output_signature = _dynamic_output_signature()\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self._generator, output_signature=output_signature)\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_transform(image):\n",
    "    L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check info from the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was initially created using the scripts `retrieve_data.ipynb` and stored in a private server for later (re)use.\n",
    "In the metadata.csv file we get the information on original link, class and coordinates of each image.\n",
    "\n",
    "NOTE: the following are links stored in a private server, jet they are still publically available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10008 entries, 0 to 10007\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   img_id      10008 non-null  int64  \n",
      " 1   img_name    10008 non-null  object \n",
      " 2   latitude    10008 non-null  float64\n",
      " 3   longitude   10008 non-null  float64\n",
      " 4   zoom_level  10008 non-null  int64  \n",
      " 5   class       10008 non-null  int64  \n",
      " 6   link        10008 non-null  object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 625.5+ KB\n"
     ]
    }
   ],
   "source": [
    "is_large_dataset = True\n",
    "\n",
    "if is_large_dataset:\n",
    "    server_port = 1986 # Large dataset of ~10K images\n",
    "else:\n",
    "    server_port = 1985 # Large dataset of ~10K images\n",
    "# server_port = 1985 # initial dataset of 3.6K images\n",
    "\n",
    "raw_data_csv_file_link = f\"https://perritos.myasustor.com:{server_port}/metadata.csv\"\n",
    "\n",
    "\n",
    "metadata_raw_df = pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "metadata_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Train, Valid and Test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the column `image_id` from the metadata as index of the images and then we perform standard shufling and splitting.\n",
    "\n",
    "The final ratio for the train, validation and test dastasets are: 70, 29 and 1 % respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size fo the train dataset is: 7005.\n",
      "the size fo the validation dataset is: 2902.\n",
      "the size fo the test dataset is: 101.\n"
     ]
    }
   ],
   "source": [
    "dataX, dataY = metadata_raw_df[\"img_id\"].to_list(), metadata_raw_df[\"class\"] .to_list()\n",
    "\n",
    "rand_state = 9898\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.29\n",
    "test_ratio = 0.01\n",
    "\n",
    "\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio, stratify = dataY, random_state=rand_state)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test, random_state=rand_state)\n",
    "\n",
    "print(f\"the size fo the train dataset is: {len(x_train)}.\\nthe size fo the validation dataset is: {len(x_val)}.\\nthe size fo the test dataset is: {len(x_test)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 64\n",
    "\n",
    "# Instantiate the dataset\n",
    "# img_indices = [0, 1, 2, 3, 4, 5]  # Example indices\n",
    "\n",
    "train_dataset_loader = SwisstopoDataset(x_test, \n",
    "                           transform=convert_to_LAB_transform, \n",
    "                           large_dataset=True, \n",
    "                           return_label=False, \n",
    "                           batch_size=b_size)\n",
    "\n",
    "test_dataset_loader = SwisstopoDataset(x_test, \n",
    "                           transform=convert_to_LAB_transform, \n",
    "                           large_dataset=True, \n",
    "                           return_label=False, \n",
    "                           batch_size=b_size)\n",
    "\n",
    "valid_dataset_loader = SwisstopoDataset(x_val, \n",
    "                           transform=convert_to_LAB_transform, \n",
    "                           large_dataset=True, \n",
    "                           return_label=False, \n",
    "                           batch_size=b_size)\n",
    "\n",
    "train_dataset = train_dataset_loader.get_dataset()\n",
    "test_dataset = test_dataset_loader.get_dataset()\n",
    "valid_dataset = valid_dataset_loader.get_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 256, 256, 1) (64, 256, 256, 2)\n"
     ]
    }
   ],
   "source": [
    "# Get the tf.data.Dataset\n",
    "\n",
    "\n",
    "# Iterate over the dataset\n",
    "for batch in train_dataset:\n",
    "    # (L_channel, AB_channels), labels = batch # print with labels\n",
    "    # print(L_channel.shape, AB_channels.shape, print(labels.shape))\n",
    "    L_channel, AB_channels= batch # print without labels\n",
    "    print(L_channel.shape, AB_channels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load \"base\" TF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load base Hyper-U-Net model from the original source:\n",
    "\n",
    "- link to [original paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9604844/)\n",
    "\n",
    "- link to [repository](https://github.com/3DOM-FBK/Hyper_U_Net?tab=readme-ov-file)\n",
    "\n",
    "- link to [model](\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
    "\n",
    "NOTE: This will download a .h5 file to your device in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
    "filename=\"Hyper_U_Net.h5\"\n",
    "\n",
    "if not os.path.exists(os.path.join(os.curdir, \"Hyper_U_Net.h5\")):\n",
    "    path, headers = urlretrieve(url, filename)\n",
    "# for name, value in headers.items():\n",
    "#     print(name, value)\n",
    "# model1 = keras.models.load_model(os.path.join(os.curdir, \"Hyper_U_Net.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 26901698\n",
      "Total parameters: 41615234\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, None, None, 64)       640       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, None, None, 64)       36928     ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 64)       0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, None, None, 128)      73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, None, None, 128)      147584    ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 128)      0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, None, None, 256)      295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, None, None, 256)      590080    ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, None, None, 256)      590080    ['conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, None, None, 256)      0         ['conv2d_6[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, None, None, 512)      1180160   ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, None, None, 512)      2359808   ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, None, None, 512)      2359808   ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, None, None, 512)      0         ['conv2d_9[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, None, None, 512)      2359808   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, None, None, 512)      0         ['conv2d_12[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, None, None, 512)      2359808   ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, None, None, 512)      0         ['conv2d_15[0][0]']           \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, None, None, 512)      1049088   ['up_sampling2d[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, None, None, 1024)     0         ['conv2d_12[0][0]',           \n",
      "                                                                     'conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, None, None, 512)      4719104   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, None, None, 512)      0         ['conv2d_18[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, None, None, 512)      1049088   ['up_sampling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, None, None, 1024)     0         ['conv2d_9[0][0]',            \n",
      " )                                                                   'conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, None, None, 512)      4719104   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, None, None, 512)      0         ['conv2d_21[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, None, None, 256)      524544    ['up_sampling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, None, None, 512)      0         ['conv2d_6[0][0]',            \n",
      " )                                                                   'conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, None, None, 256)      1179904   ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, None, None, 256)      590080    ['conv2d_23[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, None, None, 256)      0         ['conv2d_24[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, None, None, 128)      131200    ['up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, None, None, 256)      0         ['conv2d_3[0][0]',            \n",
      " )                                                                   'conv2d_25[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, None, None, 128)      295040    ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, None, None, 128)      147584    ['conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, None, None, 128)      0         ['conv2d_27[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, None, None, 64)       32832     ['up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, None, None, 128)      0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_28[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, None, None, 64)       73792     ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, None, None, 64)       36928     ['conv2d_29[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, None, None, 128)      0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSamplin  (None, None, None, 128)      0         ['conv2d_27[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, None, None, 384)      0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_30[0][0]',           \n",
      "                                                                     'up_sampling2d_5[0][0]',     \n",
      "                                                                     'up_sampling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, None, None, 128)      442496    ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, None, None, 64)       73792     ['conv2d_31[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, None, None, 64)       36928     ['conv2d_32[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, None, None, 2)        1154      ['conv2d_33[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41615234 (158.75 MB)\n",
      "Trainable params: 26901698 (102.62 MB)\n",
      "Non-trainable params: 14713536 (56.13 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model(\"Hyper_U_Net.h5\")\n",
    "\n",
    "# Find the index of the last encoder layer\n",
    "last_encoder_layer_index = loaded_model.layers.index(loaded_model.get_layer('max_pooling2d_4'))\n",
    "\n",
    "# Freeze all layers up to the last encoder layer\n",
    "for layer in loaded_model.layers[:last_encoder_layer_index + 1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Function to count the number of parameters\n",
    "def count_params(model, only_trainable=False):\n",
    "    if only_trainable:\n",
    "        return np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "    else:\n",
    "        return np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights + model.non_trainable_weights])\n",
    "\n",
    "# Get the number of trainable and non-trainable parameters\n",
    "trainable_params = count_params(loaded_model, only_trainable=True)\n",
    "total_params = count_params(loaded_model)\n",
    "\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "# Display model summary\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model after freezing the encoder layers\n",
    "loaded_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain Hpyer UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "loaded_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_dataset,\n",
    "    # callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
