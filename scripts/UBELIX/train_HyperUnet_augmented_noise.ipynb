{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPhrWUfPtbOB"
      },
      "source": [
        "# Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nOu67AemtbOD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-24 00:01:05.264823: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "# %config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [5, 5]\n",
        "from glob import glob\n",
        "import os\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "from skimage import util\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "# import albumentations as A\n",
        "# from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import v2, functional\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import io as tf_io\n",
        "\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "# Lorenz's libs\n",
        "# import math\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "# from pyproj import Proj, Transformer\n",
        "import random\n",
        "# from tqdm import tqdm\n",
        "# import folium\n",
        "# from folium.plugins import MarkerCluster\n",
        "\n",
        "from toloboy.toloboy import RGB2LAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z49vV6iBtbOF"
      },
      "source": [
        "# Define helper functions/classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6ISBDAJ7tbOF"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LTransformation(object):\n",
        "    def __init__(self, contrast_range=(0.9, 1), brightness_range=(-0.05, 0.20), noise_var_range=(0, 0.005)):\n",
        "        self.contrast_range = contrast_range\n",
        "        self.brightness_range = brightness_range\n",
        "        self.noise_var_range = noise_var_range\n",
        "\n",
        "    def _apply_factor(self, L_channel, contrast_factor, brightness_factor):\n",
        "        # Apply adjusted brightness and contrast to the L channel\n",
        "        L_adjusted = contrast_factor * L_channel + brightness_factor\n",
        "\n",
        "        # Clip adjusted L channel to [0, 1]\n",
        "        L_adjusted = np.clip(L_adjusted, 0, 1)\n",
        "\n",
        "        return L_adjusted\n",
        "\n",
        "    def _apply_noise(self, L_channel, noise_var):\n",
        "        # Apply Gaussian noise to the L channel\n",
        "        L_noisy = util.random_noise(L_channel, mode='gaussian', var=noise_var)\n",
        "\n",
        "        # Clip noisy L channel to [0, 1]\n",
        "        L_noisy = np.clip(L_noisy, 0, 1)\n",
        "\n",
        "        return L_noisy\n",
        "\n",
        "    def _randomize_factors(self):\n",
        "        return np.random.uniform(*self.brightness_range), np.random.uniform(*self.contrast_range)\n",
        "\n",
        "    def _randomize_noise_var(self):\n",
        "        return np.random.uniform(*self.noise_var_range)\n",
        "\n",
        "    def __call__(self, L_channel):\n",
        "        while True:\n",
        "            brightness_factor, contrast_factor = self._randomize_factors()\n",
        "            noise_var = self._randomize_noise_var()\n",
        "\n",
        "            # Apply adjusted brightness and contrast to the L channel\n",
        "            L_adjusted = self._apply_factor(L_channel, contrast_factor, brightness_factor)\n",
        "\n",
        "            # Apply Gaussian noise to the L channel\n",
        "            L_augmented = self._apply_noise(L_adjusted, noise_var)\n",
        "\n",
        "            # Check if values are within range\n",
        "            if 0 <= np.min(L_augmented) <= np.max(L_augmented) <= 1:\n",
        "                break\n",
        "\n",
        "        return L_augmented, contrast_factor, brightness_factor, noise_var\n",
        "\n",
        "def convert_RGB_to_feed_model(img):\n",
        "    img = np.asarray(img)\n",
        "    sz_x = img.shape[0]\n",
        "    sz_y = img.shape[1]\n",
        "\n",
        "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
        "    train_input = np.zeros((sz_x, sz_y, 1))\n",
        "\n",
        "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
        "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
        "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
        "    L, A, B = RGB2LAB(R1, G1, B1)\n",
        "\n",
        "    train_input[:, :, 0] = L.reshape((sz_x, sz_y))\n",
        "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
        "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
        "\n",
        "    return train_input, train_imgs\n",
        "\n",
        "\n",
        "def convert_RGB__and_augment_to_feed_model(img):\n",
        "    img = np.asarray(img)\n",
        "    sz_x = img.shape[0]\n",
        "    sz_y = img.shape[1]\n",
        "\n",
        "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
        "    train_input = np.zeros((sz_x, sz_y, 1))\n",
        "\n",
        "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
        "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
        "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
        "    L, A, B = RGB2LAB(R1, G1, B1)\n",
        "\n",
        "    # Apply LTransformation to the L channel\n",
        "    L_transformation = LTransformation()\n",
        "    L_augmented, _, _, _ = L_transformation(L.reshape((sz_x, sz_y)))\n",
        "\n",
        "    train_input[:, :, 0] = L_augmented\n",
        "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
        "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
        "\n",
        "    return train_input, train_imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQK5mzkJtbOF"
      },
      "source": [
        "# Define custom Dataset class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fhg4hXt7tbOF"
      },
      "outputs": [],
      "source": [
        "class SwisstopoDataset:\n",
        "    def __init__(self, img_indx, transform=None, large_dataset=False, return_label=True, batch_size=32, shuffle=False):\n",
        "        self.img_indx = img_indx\n",
        "        self.transform = transform\n",
        "        self.large_dataset = large_dataset\n",
        "        self.return_label = return_label\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Set the appropriate port based on the dataset size\n",
        "        self.port = 1986 if self.large_dataset else 1985\n",
        "\n",
        "        # Load metadata\n",
        "        self.metadata_file = self._load_metadata()\n",
        "\n",
        "    def _load_metadata(self):\n",
        "        raw_data_csv_file_link = f\"https://perritos.myasustor.com:{self.port}/metadata.csv\"\n",
        "        return pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
        "\n",
        "    def _fetch_image(self, img_id):\n",
        "        img_in_server_link = f\"https://perritos.myasustor.com:{self.port}/data/img_id_{img_id}.jpg\"\n",
        "        response = requests.get(img_in_server_link)\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "        return image\n",
        "\n",
        "    def _process_image(self, img_id):\n",
        "        image = self._fetch_image(img_id)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "            image = image / 255.0  # Default normalization\n",
        "        return image\n",
        "\n",
        "    def _get_label(self, idx):\n",
        "        return self.metadata_file[\"class\"].iloc[idx]\n",
        "\n",
        "    def _generator(self):\n",
        "        if self.shuffle:\n",
        "            img_indices = np.random.permutation(len(self.img_indx))\n",
        "        else:\n",
        "            img_indices = self.img_indx\n",
        "\n",
        "        for idx in range(len(self.img_indx)):\n",
        "            image = self._process_image(self.img_indx[idx])\n",
        "            L, AB = image  # Unpack the transformed image\n",
        "            if self.return_label:\n",
        "                label = self._get_label(idx)\n",
        "                yield (L, AB), label\n",
        "            else:\n",
        "                yield L, AB\n",
        "\n",
        "    def get_dataset(self):\n",
        "        # Dynamically infer the shapes of L and AB channels\n",
        "        def _dynamic_output_signature():\n",
        "            example_image = self._fetch_image(self.img_indx[0])\n",
        "            example_transformed = self.transform(example_image)\n",
        "            L, AB = example_transformed\n",
        "            L_shape = tf.TensorSpec(shape=L.shape, dtype=tf.float32)\n",
        "            AB_shape = tf.TensorSpec(shape=AB.shape, dtype=tf.float32)\n",
        "            if self.return_label:\n",
        "                return ((L_shape, AB_shape), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
        "            else:\n",
        "                return (L_shape, AB_shape)\n",
        "\n",
        "        output_signature = _dynamic_output_signature()\n",
        "\n",
        "        dataset = tf.data.Dataset.from_generator(self._generator, output_signature=output_signature)\n",
        "        dataset = dataset.batch(self.batch_size, drop_remainder=True) # use drop reminder to have same size always\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_Pey9rtbOG"
      },
      "source": [
        "# Define transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oG6p8WLgtbOG"
      },
      "outputs": [],
      "source": [
        "def convert_to_LAB_transform(image):\n",
        "    L, AB = convert_RGB_to_feed_model(image)\n",
        "    return (L, AB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zk55GvJ-M3sb"
      },
      "outputs": [],
      "source": [
        "def convert_to_LAB_and_augment_transform(image):\n",
        "    if np.random.rand() < 0.25:  # only apply augmentation to 25% of the data\n",
        "        L, AB = convert_RGB__and_augment_to_feed_model(image)\n",
        "    else:\n",
        "        L, AB = convert_RGB_to_feed_model(image)\n",
        "    return (L, AB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbnPPtxItbOG"
      },
      "source": [
        "# Check info from the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sv3aDOqtbOG"
      },
      "source": [
        "The data was initially created using the scripts `retrieve_data.ipynb` and stored in a private server for later (re)use.\n",
        "In the metadata.csv file we get the information on original link, class and coordinates of each image.\n",
        "\n",
        "NOTE: the following are links stored in a private server, jet they are still publically available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4m9m1QstbOG",
        "outputId": "60de97b0-b9e3-49a5-a4c8-4006956dc863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 10008 entries, 0 to 10007\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   img_id      10008 non-null  int64  \n",
            " 1   img_name    10008 non-null  object \n",
            " 2   latitude    10008 non-null  float64\n",
            " 3   longitude   10008 non-null  float64\n",
            " 4   zoom_level  10008 non-null  int64  \n",
            " 5   class       10008 non-null  int64  \n",
            " 6   link        10008 non-null  object \n",
            "dtypes: float64(2), int64(3), object(2)\n",
            "memory usage: 625.5+ KB\n"
          ]
        }
      ],
      "source": [
        "is_large_dataset = True\n",
        "\n",
        "if is_large_dataset:\n",
        "    server_port = 1986 # Large dataset of ~10K images\n",
        "else:\n",
        "    server_port = 1985 # Large dataset of ~10K images\n",
        "# server_port = 1985 # initial dataset of 3.6K images\n",
        "\n",
        "raw_data_csv_file_link = f\"https://perritos.myasustor.com:{server_port}/metadata.csv\"\n",
        "\n",
        "\n",
        "metadata_raw_df = pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
        "metadata_raw_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qdE4zTGtbOG"
      },
      "source": [
        "# Split the Train, Valid and Test subsets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bixi8SetbOG"
      },
      "source": [
        "We use the column `image_id` from the metadata as index of the images and then we perform standard shufling and splitting.\n",
        "\n",
        "The final ratio for the train, validation and test dastasets are: 70, 29 and 1 % respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTY8A1yltbOG",
        "outputId": "c5f8eacf-71df-498c-e6b8-873bc8c86cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the size fo the train dataset is: 7005.\n",
            "the size fo the validation dataset is: 2902.\n",
            "the size fo the test dataset is: 101.\n"
          ]
        }
      ],
      "source": [
        "dataX, dataY = metadata_raw_df[\"img_id\"].to_list(), metadata_raw_df[\"class\"] .to_list()\n",
        "\n",
        "rand_state = 9898\n",
        "train_ratio = 0.70\n",
        "validation_ratio = 0.29\n",
        "test_ratio = 0.01\n",
        "\n",
        "\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio, stratify = dataY, random_state=rand_state)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test, random_state=rand_state)\n",
        "\n",
        "print(f\"the size fo the train dataset is: {len(x_train)}.\\nthe size fo the validation dataset is: {len(x_val)}.\\nthe size fo the test dataset is: {len(x_test)}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "b_size = 64\n",
        "\n",
        "# Instantiate the dataset\n",
        "# img_indices = [0, 1, 2, 3, 4, 5]  # Example indices\n",
        "\n",
        "train_dataset_loader = SwisstopoDataset(x_train,\n",
        "                           transform=convert_to_LAB_and_augment_transform,\n",
        "                           large_dataset=True,\n",
        "                           return_label=False,\n",
        "                           batch_size=b_size,\n",
        "                           shuffle=True)\n",
        "\n",
        "valid_dataset_loader = SwisstopoDataset(x_val,\n",
        "                           transform=convert_to_LAB_transform,\n",
        "                           large_dataset=True,\n",
        "                           return_label=False,\n",
        "                           batch_size=b_size,\n",
        "                           shuffle=False)\n",
        "\n",
        "test_dataset_loader = SwisstopoDataset(x_test,\n",
        "                           transform=convert_to_LAB_transform,\n",
        "                           large_dataset=True,\n",
        "                           return_label=False,\n",
        "                           batch_size=b_size,\n",
        "                           shuffle=False)\n",
        "\n",
        "train_dataset = train_dataset_loader.get_dataset()\n",
        "test_dataset = test_dataset_loader.get_dataset()\n",
        "valid_dataset = valid_dataset_loader.get_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 256, 256, 1) (64, 256, 256, 2)\n"
          ]
        }
      ],
      "source": [
        "# Get the tf.data.Dataset\n",
        "# Iterate over the dataset\n",
        "for batch in train_dataset:\n",
        "    # (L_channel, AB_channels), labels = batch # print with labels\n",
        "    # print(L_channel.shape, AB_channels.shape, print(labels.shape))\n",
        "    L_channel, AB_channels= batch # print without labels\n",
        "    print(L_channel.shape, AB_channels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9Dmdyh6tbOH"
      },
      "source": [
        "# Load \"base\" TF model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIFpWS05tbOH"
      },
      "source": [
        "Load base Hyper-U-Net model from the original source:\n",
        "\n",
        "- link to [original paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9604844/)\n",
        "\n",
        "- link to [repository](https://github.com/3DOM-FBK/Hyper_U_Net?tab=readme-ov-file)\n",
        "\n",
        "- link to [model](\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
        "\n",
        "NOTE: This will download a .h5 file to your device in the current directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "abDicwEotbOH"
      },
      "outputs": [],
      "source": [
        "url = (\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
        "filename=\"Hyper_U_Net.h5\"\n",
        "\n",
        "if not os.path.exists(os.path.join(os.curdir, \"Hyper_U_Net.h5\")):\n",
        "    path, headers = urlretrieve(url, filename)\n",
        "# for name, value in headers.items():\n",
        "#     print(name, value)\n",
        "# model1 = keras.models.load_model(os.path.join(os.curdir, \"Hyper_U_Net.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4PYQM4QtbOH",
        "outputId": "3ce54eed-ff97-4281-ced9-55e4fba9ff46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable parameters: 26901698\n",
            "Total parameters: 41615234\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 1)]      0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, None, None, 64)       640       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, None, None, 64)       36928     ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, None, None, 64)       0         ['conv2d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, None, None, 128)      73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, None, None, 128)      147584    ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, None, None, 128)      0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, None, None, 256)      295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, None, None, 256)      590080    ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, None, None, 256)      590080    ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, None, None, 256)      0         ['conv2d_6[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, None, None, 512)      1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, None, None, 512)      2359808   ['conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, None, None, 512)      2359808   ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, None, None, 512)      0         ['conv2d_9[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, None, None, 512)      2359808   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, None, None, 512)      0         ['conv2d_12[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, None, None, 512)      2359808   ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, None, None, 512)      0         ['conv2d_15[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, None, None, 512)      1049088   ['up_sampling2d[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, None, None, 1024)     0         ['conv2d_12[0][0]',           \n",
            "                                                                     'conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, None, None, 512)      4719104   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, None, None, 512)      0         ['conv2d_18[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, None, None, 512)      1049088   ['up_sampling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, None, None, 1024)     0         ['conv2d_9[0][0]',            \n",
            " )                                                                   'conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, None, None, 512)      4719104   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, None, None, 512)      2359808   ['conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSamplin  (None, None, None, 512)      0         ['conv2d_21[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, None, None, 256)      524544    ['up_sampling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, None, None, 512)      0         ['conv2d_6[0][0]',            \n",
            " )                                                                   'conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, None, None, 256)      1179904   ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, None, None, 256)      590080    ['conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSamplin  (None, None, None, 256)      0         ['conv2d_24[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, None, None, 128)      131200    ['up_sampling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, None, None, 256)      0         ['conv2d_3[0][0]',            \n",
            " )                                                                   'conv2d_25[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, None, None, 128)      295040    ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, None, None, 128)      147584    ['conv2d_26[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSamplin  (None, None, None, 128)      0         ['conv2d_27[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, None, None, 64)       32832     ['up_sampling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, None, None, 128)      0         ['conv2d_1[0][0]',            \n",
            " )                                                                   'conv2d_28[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, None, None, 64)       73792     ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, None, None, 64)       36928     ['conv2d_29[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSamplin  (None, None, None, 128)      0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSamplin  (None, None, None, 128)      0         ['conv2d_27[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, None, None, 384)      0         ['conv2d_1[0][0]',            \n",
            " )                                                                   'conv2d_30[0][0]',           \n",
            "                                                                     'up_sampling2d_5[0][0]',     \n",
            "                                                                     'up_sampling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, None, None, 128)      442496    ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, None, None, 64)       73792     ['conv2d_31[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, None, None, 64)       36928     ['conv2d_32[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, None, None, 2)        1154      ['conv2d_33[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 41615234 (158.75 MB)\n",
            "Trainable params: 26901698 (102.62 MB)\n",
            "Non-trainable params: 14713536 (56.13 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model(\"Hyper_U_Net.h5\")\n",
        "\n",
        "# Find the index of the last encoder layer\n",
        "last_encoder_layer_index = loaded_model.layers.index(loaded_model.get_layer('max_pooling2d_4'))\n",
        "\n",
        "# Freeze all layers up to the last encoder layer\n",
        "for layer in loaded_model.layers[:last_encoder_layer_index + 1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Function to count the number of parameters\n",
        "def count_params(model, only_trainable=False):\n",
        "    if only_trainable:\n",
        "        return np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "    else:\n",
        "        return np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights + model.non_trainable_weights])\n",
        "\n",
        "# Get the number of trainable and non-trainable parameters\n",
        "trainable_params = count_params(loaded_model, only_trainable=True)\n",
        "total_params = count_params(loaded_model)\n",
        "\n",
        "print(f\"Trainable parameters: {trainable_params}\")\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "\n",
        "# Display model summary\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fLF4e2w6tbOI"
      },
      "outputs": [],
      "source": [
        "# Compile the model after freezing the encoder layers\n",
        "loaded_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrain Hyper UNet (**with** Transformations)\n",
        "\n",
        "NOTE: **Rename this for each intsance of new training or leave it if you are resuming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******* making new dir to store model @: '/Users/rubencito/Library/Mobile Documents/com~apple~CloudDocs/programming_stuff/CAS_AML/Final_project/AML_FinalProject/models/HyperUnet_retrain_augmented_noise' *******\n"
          ]
        }
      ],
      "source": [
        "epochs = 30\n",
        "name = \"HyperUnet_retrain_augmented_noise\"\n",
        "checkpoint_path = os.path.abspath(\n",
        "    os.path.join(\n",
        "        os.curdir, \n",
        "        \"..\",\n",
        "        \"models\",\n",
        "        name,\n",
        "        f\"{name}_epoch{{epoch:02d}}_valloss{{val_loss:.4f}}.keras\"\n",
        "        )\n",
        "        )\n",
        "\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    print(f\"******* making new dir to store model @: '{checkpoint_dir}' *******\")\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                    save_freq='epoch',\n",
        "                                    save_best_only=False,\n",
        "                                    save_weights_only = False,\n",
        "                                    verbose=1 \n",
        "                                    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## start training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "history = loaded_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    validation_steps=4,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = loaded_model.evaluate(test_dataset)\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the training evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig(os.path.join(checkpoint_dir, f'{name}_loss.png'), dpi=100)\n",
        "# plt.savefig(sys.stdout.buffer)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot the training and validation accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.savefig(os.path.join(checkpoint_dir, f'{name}_accuracy.png'), dpi=100)\n",
        "# plt.savefig(sys.stdout.buffer)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"######### Training is done! yahoo!!!!! #########\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
