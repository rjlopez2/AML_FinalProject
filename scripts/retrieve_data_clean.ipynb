{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from time import sleep\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "\n",
    "# Lorenz's libs\n",
    "import math\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pyproj import Proj, Transformer\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions/classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SwisstopoTileFetcher Class**\n",
    "\n",
    "This class facilitates fetching map tiles from the Swisstopo WMTS service. It converts geographic coordinates (latitude and longitude) into tile indices, constructs the appropriate URL for the tile image, and downloads the image. The class also provides a method to display the fetched tile image using matplotlib.\n",
    "\n",
    "Key Methods:\n",
    "\n",
    "*   **lat_lon_to_tile_indices():** Converts latitude and longitude to tile indices based on the zoom level.\n",
    "*   **fetch_tile():** Downloads the tile image from Swisstopo.\n",
    "*   **show_tile():** Displays the fetched tile image.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "\n",
    "\n",
    "*   **longitude:** The longitude of the point for which the tile is to be fetched.\n",
    "*   **latitude:** The latitude of the point for which the tile is to be fetched.\n",
    "*   **zoom_level:** The zoom level for the map tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwisstopoTileFetcher:\n",
    "    def __init__(self, longitude, latitude, zoom_level):\n",
    "        self.scheme = \"https\"\n",
    "        self.server_name = \"wmts0.geo.admin.ch\"  # Can be wmts0 to wmts9\n",
    "        self.version = \"1.0.0\"\n",
    "        self.layer_name = \"ch.swisstopo.swissimage\"\n",
    "        self.style_name = \"default\"\n",
    "        self.time = \"current\"\n",
    "        self.tile_matrix_set = \"3857\"\n",
    "        self.format_extension = \"jpeg\"\n",
    "        self.longitude = longitude\n",
    "        self.latitude = latitude\n",
    "        self.zoom_level = zoom_level\n",
    "\n",
    "    def lat_lon_to_tile_indices(self):\n",
    "        n = 2 ** self.zoom_level\n",
    "        lat_rad = math.radians(self.latitude)\n",
    "        x_tile = int((self.longitude + 180.0) / 360.0 * n)\n",
    "        y_tile = int((1.0 - math.log(math.tan(lat_rad) + (1 / math.cos(lat_rad))) / math.pi) / 2.0 * n)\n",
    "        return x_tile, y_tile\n",
    "\n",
    "    def fetch_tile(self):\n",
    "        # Convert coordinates to tile indices\n",
    "        x, y = self.lat_lon_to_tile_indices()\n",
    "\n",
    "        # Construct the URL\n",
    "        url = f\"{self.scheme}://{self.server_name}/{self.version}/{self.layer_name}/{self.style_name}/{self.time}/{self.tile_matrix_set}/{self.zoom_level}/{x}/{y}.{self.format_extension}\"\n",
    "\n",
    "        # Download the tile\n",
    "\n",
    "        with requests.Session() as session:\n",
    "            with session.get(url) as response:\n",
    "                if response.status_code == 200:\n",
    "                    image = Image.open(BytesIO(response.content))\n",
    "                    return image, url\n",
    "                else:\n",
    "                    print(f\"Failed to download tile. Status code: {response.status_code}\")\n",
    "                    return None\n",
    "\n",
    "    def show_tile(self):\n",
    "        image = self.fetch_tile()\n",
    "        if image:\n",
    "            # Display the image\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')  # Hide the axis\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ArealstatistikSampler Class**\n",
    "\n",
    "This class is designed to sample geographic points from a dataset provided in LV95 coordinates and convert them to WGS84 coordinates. It reads the CSV file*, filters the data based on a specified column, and randomly selects a given number of points from each unique value in that column. The selected points are then transformed from the LV95 coordinate system to the WGS84 coordinate system.\n",
    "\n",
    "Key Methods:\n",
    "\n",
    "\n",
    "*   **lv95_to_wgs84(lon, lat):** Converts coordinates from LV95 to WGS84.\n",
    "*   **sample_points():** Samples the specified number of points for each unique value in the specified column, converts their coordinates, and returns a list of these points.\n",
    "\n",
    "\n",
    "Parameters:\n",
    "\n",
    "\n",
    "\n",
    "*   **file_path:** Path to the CSV file containing the data.\n",
    "*   **column_to_filter:** Column name used to filter and categorize the data.\n",
    "*   **num_samples:** Number of samples to select for each unique value in the column.\n",
    "*   **random_state:** Optional parameter to ensure reproducibility of random sampling.\n",
    "\n",
    "*available on https://www.bfs.admin.ch/bfs/en/home/services/geostat/swiss-federal-statistics-geodata/land-use-cover-suitability/swiss-land-use-statistics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArealstatistikSampler:\n",
    "    def __init__(self, file_path, column_to_filter, num_samples, random_state=None):\n",
    "        self.file_path = file_path\n",
    "        self.column_to_filter = column_to_filter\n",
    "        self.num_samples = num_samples\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def lv95_to_wgs84(self, lon, lat):\n",
    "        in_proj = Proj(\"epsg:2056\")\n",
    "        out_proj = Proj(\"epsg:4326\")\n",
    "        transformer = Transformer.from_proj(in_proj, out_proj)\n",
    "        lon_wgs84, lat_wgs84 = transformer.transform(lon, lat)\n",
    "        return lon_wgs84, lat_wgs84\n",
    "\n",
    "    def sample_points(self):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(self.file_path, delimiter=\";\")\n",
    "\n",
    "        # Filter out rows with missing values in the specified column\n",
    "        df_filtered = df.dropna(subset=[self.column_to_filter])\n",
    "\n",
    "        # Create an empty list to store the selected points\n",
    "        selected_points = []\n",
    "\n",
    "        # Set random state if provided\n",
    "        if self.random_state is not None:\n",
    "            random_state = self.random_state\n",
    "        else:\n",
    "            random_state = 42  # Default random state\n",
    "            \n",
    "        n_classes = df_filtered[self.column_to_filter].unique()\n",
    "\n",
    "        # Iterate over each unique value in the specified column\n",
    "        for class_value in n_classes:\n",
    "            # Filter rows for the current class value\n",
    "            class_df = df_filtered[df_filtered[self.column_to_filter] == class_value]\n",
    "\n",
    "            # Randomly select specified number of examples for the current class value\n",
    "            selected_samples = class_df.sample(n=self.num_samples, random_state=random_state)\n",
    "\n",
    "            # Convert LV95 coordinates to WGS84 and store them in the selected_points list\n",
    "            for _, row in selected_samples.iterrows():\n",
    "                lon_wgs84, lat_wgs84 = self.lv95_to_wgs84(row[\"E_COORD\"], row[\"N_COORD\"])\n",
    "                selected_points.append([lon_wgs84, lat_wgs84, class_value])\n",
    "\n",
    "        return selected_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/content/drive/MyDrive/CAS Avanced Machine Learning/Luftbild_Colarization/ag-b-00.03-37-area-csv.csv\"\n",
    "file_path = \"/Volumes/Ruben/datasets/land_use_data/ag-b-00.03-37-area-csv.csv\"\n",
    "column_to_filter = \"AS18_72\" #column in the dataset with the classes\n",
    "num_samples = 139  #number of samples per class, NOTE: I found out that the lower number of samples from class is 461, so larger number than this will give an error!\n",
    "random_state = 42\n",
    "zoom_levels = [16, 17, 18] #zoom levels to fetch images from randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect sample points and show the spatial distribution on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples collected: 10008\n"
     ]
    }
   ],
   "source": [
    "# Instantiate ArealstatistikSampler and sample points\n",
    "sampler = ArealstatistikSampler(file_path, column_to_filter, num_samples, random_state)\n",
    "coordinates = sampler.sample_points()\n",
    "\n",
    "# Print the number of samples collected\n",
    "print(\"Number of samples collected:\", len(coordinates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to make a faster fetcher class with concurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_images_with_random_zoom_levels_faster(point, indx, zoom_levels, save_to = None):\n",
    "    \"\"\"\n",
    "    Fetch images for sampled points using random zoom levels.\n",
    "\n",
    "    Args:\n",
    "        sampled_points (list): List of sampled points, where each point is represented as a list [lat, lon] or [lat, lon, class_value].\n",
    "        zoom_levels (list): List of zoom levels to choose from.\n",
    "        save_to (str): if provided, valid path where to save the  fetched image.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries, each containing fetched image and its metadata (lat, lon, zoom_level, class).\n",
    "    \"\"\"\n",
    "\n",
    "    lat, lon = point[:2]  # Extract latitude and longitude\n",
    "    class_value = point[2] if len(point) > 2 else None\n",
    "    zoom_level = random.choice(zoom_levels)\n",
    "    tile_fetcher = SwisstopoTileFetcher(lon, lat, zoom_level)\n",
    "    image, url = tile_fetcher.fetch_tile()\n",
    "    sleep(0.15)\n",
    "    image_data = {\n",
    "        'img_id': indx,\n",
    "        'img_name': '_'.join(url.split(\"/\")[-4:]).split(\".\")[0],\n",
    "        'image': image,\n",
    "        'latitude': lat,\n",
    "        'longitude': lon,\n",
    "        'zoom_level': zoom_level,\n",
    "        'class': class_value,\n",
    "        'link':url, \n",
    "    }\n",
    "\n",
    "    if save_to:\n",
    "        assert isinstance(save_to, str), \"Path must be a valid string.\"\n",
    "        assert os.path.exists(save_to), f\"The path proveided '{save_to}' was not found. Make sure that there exists!\"\n",
    "\n",
    "        data_path = os.path.join(save_to, \"data\")\n",
    "        if not os.path.exists(data_path):\n",
    "            os.makedirs(data_path, exist_ok=True)\n",
    "        # print(f\"saving img_id: {indx}\")\n",
    "        image.save(os.path.join(data_path, f\"img_id_{image_data['img_id']}.jpg\"))\n",
    "           \n",
    "\n",
    "    return image_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set multithreading to fetch images concurrently.\n",
    "This allows to speed significanlthly the download time of the images, when is a large number ~10.000 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import random\n",
    "# import os\n",
    "\n",
    "def fetch_images_concurrently(sampled_points, zoom_levels, save_to=None):\n",
    "    \"\"\"\n",
    "    Fetch images for sampled points concurrently using random zoom levels.\n",
    "\n",
    "    Args:\n",
    "        sampled_points (list): List of sampled points, where each point is represented as a list [lat, lon] or [lat, lon, class_value].\n",
    "        zoom_levels (list): List of zoom levels to choose from.\n",
    "        save_to (str): Optional path where to save the fetched images.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries, each containing fetched image and its metadata (lat, lon, zoom_level, class).\n",
    "    \"\"\"\n",
    "    def worker(point, indx):\n",
    "        return fetch_images_with_random_zoom_levels_faster(point, indx, zoom_levels, save_to)\n",
    "\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_point = {executor.submit(worker, point, indx): (point, indx) for indx, point in enumerate(sampled_points)}\n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_point), total=len(future_to_point), desc=\"Fetching images\"):\n",
    "            point, indx = future_to_point[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching image for point {point} with index {indx}: {e}\")\n",
    "    \n",
    "    if save_to:\n",
    "        print(\"saving metadata\")\n",
    "        my_df = pd.DataFrame([ {key: d[key] for key in d if key != \"image\"} for d in results])\n",
    "        my_df.sort_values(by=['img_id'], ignore_index=True, inplace=True)\n",
    "        my_df.to_csv(os.path.join(save_to, \"metadata.csv\"))\n",
    "\n",
    "    print(\"#### Done ####\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the images from the given coordinates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching images: 100%|██████████| 10008/10008 [12:22<00:00, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving metadata\n",
      "#### Done ####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the images\n",
    "# Fetch the images\n",
    "path_to_save_raw_images = r\"/Volumes/Ruben/datasets/fetched_raw_imgs_via_api_full\"\n",
    "# path_to_save_raw_images = r\"/Volumes/Ruben/datasets/fetched_raw_imgs_via_api\"\n",
    "    \n",
    "# fetched_images = fetch_images_with_random_zoom_levels(coordinates, zoom_levels, save_to=path_to_save_raw_images)\n",
    "fetched_images = fetch_images_concurrently(coordinates, zoom_levels, path_to_save_raw_images)\n",
    "len(fetched_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
