{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch\n",
    "# !pip install --upgrade tensorflow\n",
    "# !pip install --upgrade jax\n",
    "# !pip install --upgrade keras-nlp\n",
    "# !pip install --upgrade keras-cv\n",
    "# !pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 11:41:01.194632: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import util\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from toloboy.toloboy import RGB2LAB, from_LAB_to_RGB_img\n",
    "from tqdm import tqdm\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "from skimage.color import deltaE_ciede2000\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions/classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def mse(imageA, imageB, nband = 3):\n",
    "# \t# the 'Mean Squared Error' between the two images is the\n",
    "# \t# sum of the squared difference between the two images;\n",
    "# \t# NOTE: the two images must have the same dimension\n",
    "# \terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "# \terr /= float(imageA.shape[0] * imageA.shape[1] * nband)\n",
    "\t\n",
    "# \t# return the MSE, the lower the error, the more \"similar\"\n",
    "# \t# the two images are\n",
    "# \treturn err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rmse(imageA, imageB, nband):\n",
    "# \t# the 'Root Mean Squared Error' between the two images is the\n",
    "# \t# sum of the squared difference between the two images;\n",
    "# \t# NOTE: the two images must have the same dimension\n",
    "# \terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "# \terr /= float(imageA.shape[0] * imageA.shape[1] * nband)\n",
    "# \terr = np.sqrt(err)\n",
    "# \treturn err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mae(imageA, imageB, bands):\n",
    "\t# the 'Mean Absolute Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum(np.abs(imageA.astype(\"float\") - imageB.astype(\"float\")))\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1] * bands)\n",
    "\treturn err\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def psnr(img1, img2):\n",
    "    # Compute The peak signal-to-noise ratio (PSNR)\n",
    "    # Higher PSNR values indicate a higher quality of the predicted image.\n",
    "    mse = np.mean( (img1.astype(\"float\") - img2.astype(\"float\")) ** 2 )\n",
    "    # print(mse)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_e_cie2000(img0_rgb,imag1_RGB,Kl=1, KC=1, KH=1):\n",
    "    \n",
    "    Lab1 = cv2.cvtColor(img0_rgb, cv2.COLOR_BGR2Lab)\n",
    "    Lab2 = cv2.cvtColor(imag1_RGB, cv2.COLOR_BGR2Lab)\n",
    "    L1, a1, b1 = cv2.split(Lab1)\n",
    "    L2, a2, b2 = cv2.split(Lab2)\n",
    "    \n",
    "    \n",
    "    delta=deltaE_ciede2000(L1,L2, Kl, KC, KH)\n",
    "    #print(len(delta))\n",
    "    \n",
    "    return np.mean(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom Dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwisstopoDataset:\n",
    "    def __init__(self, img_indx, transform=None, large_dataset=False, return_label=True, batch_size=32, shuffle=False):\n",
    "        self.img_indx = img_indx\n",
    "        self.transform = transform\n",
    "        self.large_dataset = large_dataset\n",
    "        self.return_label = return_label\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Set the appropriate port based on the dataset size\n",
    "        self.port = 1986 if self.large_dataset else 1985\n",
    "\n",
    "        # Load metadata\n",
    "        self.metadata_file = self._load_metadata()\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        raw_data_csv_file_link = f\"https://perritos.myasustor.com:{self.port}/metadata.csv\"\n",
    "        return pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "\n",
    "    def _fetch_image(self, img_id):\n",
    "        img_in_server_link = f\"https://perritos.myasustor.com:{self.port}/data/img_id_{img_id}.jpg\"\n",
    "        response = requests.get(img_in_server_link)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "\n",
    "    def _process_image(self, img_id):\n",
    "        image = self._fetch_image(img_id)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            image = image / 255.0  # Default normalization\n",
    "        return image\n",
    "\n",
    "    def _get_label(self, idx):\n",
    "        return self.metadata_file[\"class\"].iloc[idx]\n",
    "\n",
    "    def _generator(self):\n",
    "        if self.shuffle:\n",
    "            img_indices = np.random.permutation(len(self.img_indx))\n",
    "        else:\n",
    "            img_indices = self.img_indx\n",
    "\n",
    "        for idx in range(len(self.img_indx)):\n",
    "            image = self._process_image(self.img_indx[idx])\n",
    "            L, AB = image  # Unpack the transformed image\n",
    "            if self.return_label:\n",
    "                label = self._get_label(idx)\n",
    "                yield (L, AB), label\n",
    "            else:\n",
    "                yield L, AB\n",
    "\n",
    "    def get_dataset(self):\n",
    "        # Dynamically infer the shapes of L and AB channels\n",
    "        def _dynamic_output_signature():\n",
    "            example_image = self._fetch_image(self.img_indx[0])\n",
    "            example_transformed = self.transform(example_image)\n",
    "            L, AB = example_transformed\n",
    "            L_shape = tf.TensorSpec(shape=L.shape, dtype=tf.float32)\n",
    "            AB_shape = tf.TensorSpec(shape=AB.shape, dtype=tf.float32)\n",
    "            if self.return_label:\n",
    "                return ((L_shape, AB_shape), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
    "            else:\n",
    "                return (L_shape, AB_shape)\n",
    "\n",
    "        output_signature = _dynamic_output_signature()\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self._generator, output_signature=output_signature)\n",
    "        dataset = dataset.batch(self.batch_size, drop_remainder=True) # use drop reminder to have same size always\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LTransformation(object):\n",
    "    def __init__(self, contrast_range=(0.9, 1), brightness_range=(-0.05, 0.20), noise_var_range=(0, 0.005)):\n",
    "        self.contrast_range = contrast_range\n",
    "        self.brightness_range = brightness_range\n",
    "        self.noise_var_range = noise_var_range\n",
    "\n",
    "    def _apply_factor(self, L_channel, contrast_factor, brightness_factor):\n",
    "        # Apply adjusted brightness and contrast to the L channel\n",
    "        L_adjusted = contrast_factor * L_channel + brightness_factor\n",
    "\n",
    "        # Clip adjusted L channel to [0, 1]\n",
    "        L_adjusted = np.clip(L_adjusted, 0, 1)\n",
    "\n",
    "        return L_adjusted\n",
    "\n",
    "    def _apply_noise(self, L_channel, noise_var):\n",
    "        # Apply Gaussian noise to the L channel\n",
    "        L_noisy = util.random_noise(L_channel, mode='gaussian', var=noise_var)\n",
    "\n",
    "        # Clip noisy L channel to [0, 1]\n",
    "        L_noisy = np.clip(L_noisy, 0, 1)\n",
    "\n",
    "        return L_noisy\n",
    "\n",
    "    def _randomize_factors(self):\n",
    "        return np.random.uniform(*self.brightness_range), np.random.uniform(*self.contrast_range)\n",
    "\n",
    "    def _randomize_noise_var(self):\n",
    "        return np.random.uniform(*self.noise_var_range)\n",
    "\n",
    "    def __call__(self, L_channel):\n",
    "        while True:\n",
    "            brightness_factor, contrast_factor = self._randomize_factors()\n",
    "            noise_var = self._randomize_noise_var()\n",
    "\n",
    "            # Apply adjusted brightness and contrast to the L channel\n",
    "            L_adjusted = self._apply_factor(L_channel, contrast_factor, brightness_factor)\n",
    "\n",
    "            # Apply Gaussian noise to the L channel\n",
    "            L_augmented = self._apply_noise(L_adjusted, noise_var)\n",
    "\n",
    "            # Check if values are within range\n",
    "            if 0 <= np.min(L_augmented) <= np.max(L_augmented) <= 1:\n",
    "                break\n",
    "\n",
    "        return L_augmented, contrast_factor, brightness_factor, noise_var\n",
    "\n",
    "def convert_RGB_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB(R1, G1, B1)\n",
    "\n",
    "    train_input[:, :, 0] = L.reshape((sz_x, sz_y))\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs\n",
    "\n",
    "\n",
    "def convert_RGB__and_augment_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB(R1, G1, B1)\n",
    "\n",
    "    # Apply LTransformation to the L channel\n",
    "    L_transformation = LTransformation()\n",
    "    L_augmented, _, _, _ = L_transformation(L.reshape((sz_x, sz_y)))\n",
    "\n",
    "    train_input[:, :, 0] = L_augmented\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_transform(image):\n",
    "    L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_and_augment_transform(image):\n",
    "    if np.random.rand() < 0.25:  # only apply augmentation to 25% of the data\n",
    "        L, AB = convert_RGB__and_augment_to_feed_model(image)\n",
    "    else:\n",
    "        L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check info from the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was initially created using the scripts `retrieve_data.ipynb` and stored in a private server for later (re)use.\n",
    "In the metadata.csv file we get the information on original link, class and coordinates of each image.\n",
    "\n",
    "NOTE: the following are links stored in a private server, jet they are still publically available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10008 entries, 0 to 10007\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   img_id      10008 non-null  int64  \n",
      " 1   img_name    10008 non-null  object \n",
      " 2   latitude    10008 non-null  float64\n",
      " 3   longitude   10008 non-null  float64\n",
      " 4   zoom_level  10008 non-null  int64  \n",
      " 5   class       10008 non-null  int64  \n",
      " 6   link        10008 non-null  object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 625.5+ KB\n"
     ]
    }
   ],
   "source": [
    "is_large_dataset = True\n",
    "\n",
    "if is_large_dataset:\n",
    "    server_port = 1986 # Large dataset of ~10K images\n",
    "else:\n",
    "    server_port = 1985 # Large dataset of ~10K images\n",
    "# server_port = 1985 # initial dataset of 3.6K images\n",
    "\n",
    "raw_data_csv_file_link = f\"https://perritos.myasustor.com:{server_port}/metadata.csv\"\n",
    "\n",
    "\n",
    "metadata_raw_df = pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "metadata_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Train, Valid and Test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the column `image_id` from the metadata as index of the images and then we perform standard shufling and splitting.\n",
    "\n",
    "The final ratio for the train, validation and test dastasets are: 70, 29 and 1 % respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size fo the train dataset is: 7005.\n",
      "the size fo the validation dataset is: 2902.\n",
      "the size fo the test dataset is: 101.\n"
     ]
    }
   ],
   "source": [
    "dataX, dataY = metadata_raw_df[\"img_id\"].to_list(), metadata_raw_df[\"class\"] .to_list()\n",
    "\n",
    "rand_state = 9898\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.29\n",
    "test_ratio = 0.01\n",
    "\n",
    "\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio, stratify = dataY, random_state=rand_state)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test, random_state=rand_state)\n",
    "\n",
    "print(f\"the size fo the train dataset is: {len(x_train)}.\\nthe size fo the validation dataset is: {len(x_val)}.\\nthe size fo the test dataset is: {len(x_test)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 1\n",
    "\n",
    "# Instantiate the dataset\n",
    "# img_indices = [0, 1, 2, 3, 4, 5]  # Example indices\n",
    "\n",
    "\n",
    "\n",
    "test_dataset_loader = SwisstopoDataset(x_test,\n",
    "                           transform=convert_to_LAB_transform,\n",
    "                           large_dataset=True,\n",
    "                           return_label=True,\n",
    "                           batch_size=b_size,\n",
    "                           shuffle=False)\n",
    "\n",
    "# train_dataset = train_dataset_loader.get_dataset()\n",
    "test_dataset = test_dataset_loader.get_dataset()\n",
    "# valid_dataset = valid_dataset_loader.get_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tf.data.Dataset\n",
    "# Iterate over the dataset\n",
    "# for batch in test_dataset:\n",
    "#     # (L_channel, AB_channels), labels = batch # print with labels\n",
    "#     # print(L_channel.shape, AB_channels.shape, print(labels.shape))\n",
    "#     L_channel, AB_channels= batch # print without labels\n",
    "#     print(L_channel.shape, AB_channels.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional info about the base *Hyper-U-Net* model can be found at the following sources:\n",
    "\n",
    "- link to [original paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9604844/)\n",
    "\n",
    "- link to [repository](https://github.com/3DOM-FBK/Hyper_U_Net?tab=readme-ov-file)\n",
    "\n",
    "- link to [model](\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
    "\n",
    "NOTE: This will download a multiples large files to your device in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if model is in the current directory otherwise download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: base_model\n",
      "URL: https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\n",
      "\n",
      "Model Name: HyperUnet_retrain_augmented_noise_corrected_Adam\n",
      "URL: https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_Adam/HyperUnet_retrain_augmented_noise_corrected_Adam_ckpt_epoch30_valloss0.0249.keras\n",
      "\n",
      "Model Name: HyperUnet_retrain_augmented_noise_corrected_rmsprop\n",
      "URL: https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_rmsprop/HyperUnet_retrain_augmented_noise_corrected_rmsprop_ckpt_epoch30_valloss0.0248.keras\n",
      "\n",
      "Model Name: HyperUnet_retrain_no_augmented_corrected_Adam\n",
      "URL: https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_no_augmented_corrected_Adam/HyperUnet_retrain_no_augmented_corrected_Adam_ckpt_epoch30_valloss0.0243.keras\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_sources = {\n",
    "    \"model_name\": [\n",
    "        \"base_model\",\n",
    "        # \"HyperUnet_retrained_30e\",\n",
    "        # \"HyperUnet_retrain_augmented_30e\",\n",
    "        # \"HyperUnet_retrain_augmented_noise_25e\",\n",
    "        \"HyperUnet_retrain_augmented_noise_corrected_Adam\",\n",
    "        \"HyperUnet_retrain_augmented_noise_corrected_rmsprop\",\n",
    "        \"HyperUnet_retrain_no_augmented_corrected_Adam\",\n",
    "          ],\n",
    "    \"url\": [\n",
    "        \"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrained_30e/HyperUnet_retrain1.keras\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented/HyperUnet_retrain_augmented_epoch30_valloss0.0011.keras\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise/HyperUnet_retrain_augmented_noise_ckpt_epoch25_valloss0.0010.keras\",\n",
    "        \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_Adam/HyperUnet_retrain_augmented_noise_corrected_Adam_ckpt_epoch30_valloss0.0249.keras\",\n",
    "        \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_rmsprop/HyperUnet_retrain_augmented_noise_corrected_rmsprop_ckpt_epoch30_valloss0.0248.keras\",\n",
    "        \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_no_augmented_corrected_Adam/HyperUnet_retrain_no_augmented_corrected_Adam_ckpt_epoch30_valloss0.0243.keras\",\n",
    "        ],\n",
    "    \"extension\": [\n",
    "        \"h5\",\n",
    "        # \"keras\",\n",
    "        # \"keras\",\n",
    "        # \"keras\",\n",
    "        \"keras\",\n",
    "        \"keras\",\n",
    "        \"keras\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    model_name = models_sources[\"model_name\"][i]\n",
    "    url = models_sources[\"url\"][i]\n",
    "    print(f\"Model Name: {model_name}\\nURL: {url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### No model to load, everything is in the current directory ##############\n",
      "########### No model to load, everything is in the current directory ##############\n",
      "########### No model to load, everything is in the current directory ##############\n",
      "########### No model to load, everything is in the current directory ##############\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    file_name = models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]\n",
    "    if not os.path.exists(os.path.join(os.curdir,file_name)):\n",
    "        model_url = models_sources['url'][i]\n",
    "        !wget -O {file_name}  \"$model_url\"\n",
    "    else:\n",
    "        print(\"########### No model to load, everything is in the current directory ##############\")\n",
    "    # !wget -O {models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]} {models_sources[\"url\"][i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** loading 'base_model.h5' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rubencito/micromamba/envs/colorization/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n",
      "***** loading 'HyperUnet_retrain_augmented_noise_corrected_Adam.keras' *****\n",
      "***** done *****\n",
      "***** loading 'HyperUnet_retrain_augmented_noise_corrected_rmsprop.keras' *****\n",
      "***** done *****\n",
      "***** loading 'HyperUnet_retrain_no_augmented_corrected_Adam.keras' *****\n",
      "***** done *****\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {}\n",
    "\n",
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    file_name = models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]\n",
    "    # print(f\"{'*'*5} loading '{models_sources['model_name'][i]}' {'*'*5}\")\n",
    "    print(f\"{'*'*5} loading '{file_name}' {'*'*5}\")\n",
    "    models[models_sources[\"model_name\"][i]] = load_model(file_name)\n",
    "    print(f\"{'*'*5} done {'*'*5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the main loop to compute the metrics.\n",
    "\n",
    "- We use the *Test* tadates of about 100 images.\n",
    "\n",
    "- First we pass the L channel (grey image) to the model to make the prediction.\n",
    "\n",
    "- Then we transform the **original** AND the **predicted** L\\*a\\*b images to RGB colorspace and plot them to compare results.\n",
    "\n",
    "- Finally we compute a number of metrics and summarize the results in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_model': <Functional name=model, built=True>,\n",
       " 'HyperUnet_retrain_augmented_noise_corrected_Adam': <Functional name=model, built=True>,\n",
       " 'HyperUnet_retrain_augmented_noise_corrected_rmsprop': <Functional name=model, built=True>,\n",
       " 'HyperUnet_retrain_no_augmented_corrected_Adam': <Functional name=model, built=True>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n_imgs_to_test = len(test_dataset)\n",
    "def evaluate_model_metrics(sample, model, model_name, n_samples):\n",
    "\n",
    "    \n",
    "    deltaE_list = []\n",
    "    MAE_list = []\n",
    "    PSNR_list = []\n",
    "    SSIM_list = []\n",
    "    # MSE_list = []\n",
    "    # MSEr_list = []\n",
    "    # MSEg_list = []\n",
    "    # MSEb_list = []\n",
    "    # RMSE_list = []\n",
    "\n",
    "    for data in tqdm(sample, desc = f\"evaluating model: '{model_name}'\", total=n_samples):\n",
    "\n",
    "        (L, AB), label = data\n",
    "        # print(type(L))\n",
    "        # # L = tf.squeeze(L)\n",
    "        # print(L.shape)\n",
    "        # print(type(AB))\n",
    "        # print(AB.shape)\n",
    "        # print(type(label))\n",
    "        # print(label.shape)\n",
    "        # my_model = models[\"base_model\"]\n",
    "        predicted_AB = model.predict(L, verbose=0)\n",
    "        predicted_RGB = from_LAB_to_RGB_img(L[0, ...], predicted_AB)\n",
    "        original_RGB = from_LAB_to_RGB_img(L[0, ...], AB)\n",
    "        # print(f\"Shape of original RGB is :{original_RGB.shape}\")\n",
    "        # print(\"*** Computing metrics ***\")\n",
    "        MAE = mae(original_RGB,predicted_RGB,3)\n",
    "        # MSE = mse(original_RGB,predicted_RGB,3)\n",
    "        # MSEr = mse(original_RGB[:,:,0],predicted_RGB[:,:,0],1)\n",
    "        # MSEg = mse(original_RGB[:,:,1],predicted_RGB[:,:,1],1)\n",
    "        # MSEb = mse(original_RGB[:,:,2],predicted_RGB[:,:,2],1)\n",
    "        # RMSE = rmse(original_RGB,predicted_RGB,3) # mae(imagt255,predicted_RGB,bands)\n",
    "            # PSNR = tf.image.psnr(, predicted_RGB , max_val=255)\n",
    "        PSNR= psnr(original_RGB,predicted_RGB)\n",
    "        SSIM, _ = ssim(original_RGB, predicted_RGB, channel_axis=2, full=True) # NOTE: need to specify axis channels, otherwise complains!\n",
    "\n",
    "\n",
    "        \n",
    "        deltaE = compute_delta_e_cie2000(original_RGB, predicted_RGB)\n",
    "                    \n",
    "        MAE_list.append(MAE)\n",
    "        SSIM_list.append(SSIM)\n",
    "        PSNR_list.append(PSNR)\n",
    "        deltaE_list.append(deltaE)\n",
    "        # MSE_list.append(MSE)\n",
    "        # MSEr_list.append(MSEr)\n",
    "        # MSEg_list.append(MSEg)\n",
    "        # MSEb_list.append(MSEb)\n",
    "        # RMSE_list.append(RMSE)  \n",
    "\n",
    "\n",
    "    # metrics_df = pd.DataFrame({\n",
    "    # \"Model\": model_name,\n",
    "    # \"MSE\" : MSE_list,\n",
    "    # \"PSNR\" : PSNR_list,\n",
    "    # \"MSEr\" : MSEr_list,\n",
    "    # \"MSEg\" : MSEg_list,\n",
    "    # \"MSEb\" : MSEb_list,\n",
    "    # \"RMSE\" : RMSE_list,\n",
    "    # \"SSIM\" : SSIM_list,\n",
    "    # })\n",
    "    metrics_dict = {\n",
    "    \"Model\": model_name,\n",
    "    \"dE2000\": deltaE_list,\n",
    "    \"MAE\" : MAE_list,\n",
    "    \"PSNR\" : PSNR_list,\n",
    "    \"SSIM\" : SSIM_list,\n",
    "    # \"MSE\" : MSE_list,\n",
    "    # \"MSEr\" : MSEr_list,\n",
    "    # \"MSEg\" : MSEg_list,\n",
    "    # \"MSEb\" : MSEb_list,\n",
    "    # \"RMSE\" : RMSE_list,\n",
    "    }\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** assesing model: 'base_model' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating model: 'base_model': 100%|██████████| 100/100 [01:05<00:00,  1.43it/s]2024-07-23 13:01:44.086618: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "evaluating model: 'base_model': 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n",
      "***** assesing model: 'HyperUnet_retrain_augmented_noise_corrected_Adam' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating model: 'HyperUnet_retrain_augmented_noise_corrected_Adam': 100%|██████████| 100/100 [01:18<00:00,  1.27it/s]2024-07-23 13:03:02.926510: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "evaluating model: 'HyperUnet_retrain_augmented_noise_corrected_Adam': 100%|██████████| 100/100 [01:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n",
      "***** assesing model: 'HyperUnet_retrain_augmented_noise_corrected_rmsprop' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating model: 'HyperUnet_retrain_augmented_noise_corrected_rmsprop': 100%|██████████| 100/100 [01:23<00:00,  1.27it/s]2024-07-23 13:04:26.170461: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "evaluating model: 'HyperUnet_retrain_augmented_noise_corrected_rmsprop': 100%|██████████| 100/100 [01:23<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n",
      "***** assesing model: 'HyperUnet_retrain_no_augmented_corrected_Adam' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating model: 'HyperUnet_retrain_no_augmented_corrected_Adam': 100%|██████████| 100/100 [01:20<00:00,  1.25it/s]2024-07-23 13:05:46.925422: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "evaluating model: 'HyperUnet_retrain_no_augmented_corrected_Adam': 100%|██████████| 100/100 [01:20<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "data_to_test = test_dataset.take(n_samples)\n",
    "\n",
    "metrics_all_list = []\n",
    "\n",
    "for indx, model in enumerate(models):\n",
    "    print(f\"{'*'*5} assesing model: '{model}' {'*'*5}\")\n",
    "    # if indx > 0:\n",
    "    # for sample in tqdm(data_to_test):\n",
    "    result = evaluate_model_metrics(data_to_test, models[model], model, n_samples)\n",
    "    \n",
    "    metrics_all_list.append(result)\n",
    "    print(f\"{'*'*5} done {'*'*5}\")\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Model   400 non-null    object \n",
      " 1   dE2000  400 non-null    float64\n",
      " 2   MAE     400 non-null    float64\n",
      " 3   PSNR    400 non-null    float64\n",
      " 4   SSIM    400 non-null    float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# numeric_columns = [\"MSE\", \"PSNR\", \"MSEr\", \"MSEg\", \"MSEb\", \"RMSE\", \"SSIM\"]\n",
    "numeric_columns = [\"dE2000\", \"MAE\", \"PSNR\", \"SSIM\"]\n",
    "metrics_df = pd.DataFrame(metrics_all_list).explode(numeric_columns, ignore_index=True)\n",
    "metrics_df[numeric_columns] = metrics_df[numeric_columns].astype(float)\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('_', ' ')\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('corrected', ' ')\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('retrain', ' ')\n",
    "# metrics_df['Model'] = [f\"Model{i}\" for i in range(8)]\n",
    "metrics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x216823810>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_grouped = metrics_df.groupby(\"Model\", as_index=False)\n",
    "metrics_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dE2000</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HyperUnet   augmented noise   Adam</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.11</td>\n",
       "      <td>33.42</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HyperUnet   augmented noise   rmsprop</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.09</td>\n",
       "      <td>33.45</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HyperUnet   no augmented   Adam</td>\n",
       "      <td>1.01</td>\n",
       "      <td>4.01</td>\n",
       "      <td>33.62</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base model</td>\n",
       "      <td>1.76</td>\n",
       "      <td>10.35</td>\n",
       "      <td>25.42</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  dE2000    MAE   PSNR  SSIM\n",
       "0     HyperUnet   augmented noise   Adam    1.02   4.11  33.42  0.99\n",
       "1  HyperUnet   augmented noise   rmsprop    1.02   4.09  33.45  0.99\n",
       "2        HyperUnet   no augmented   Adam    1.01   4.01  33.62  0.99\n",
       "3                             base model    1.76  10.35  25.42  0.97"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# metrics_df.groupby(\"Model\", as_index=False).mean().round(2).to_csv(\"metrics_df_mean.csv\", index=False)\n",
    "metrics_df_mean = metrics_df_grouped.mean().round(2)\n",
    "# metrics_df_mean[\"Model\"] = [f\"Model{i}\" for i in range(7)]\n",
    "# metrics_df_mean.to_csv(\"metrics_df_mean.csv\", index=False)\n",
    "metrics_df_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dE2000</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HyperUnet   augmented noise   Adam</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HyperUnet   augmented noise   rmsprop</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HyperUnet   no augmented   Adam</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base model</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  dE2000  MAE  PSNR  SSIM\n",
       "0     HyperUnet   augmented noise   Adam     0.5  1.3   2.6   0.0\n",
       "1  HyperUnet   augmented noise   rmsprop     0.5  1.3   2.7   0.0\n",
       "2        HyperUnet   no augmented   Adam     0.5  1.3   2.7   0.0\n",
       "3                             base model     0.8  3.7   3.0   0.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics_df_std = metrics_df_grouped.std().round(1)\n",
    "# metrics_df_mean[\"Model\"] = [f\"Model{i}\" for i in range(7)]\n",
    "# metrics_df_std.to_csv(\"metrics_std.csv\", index=False)\n",
    "metrics_df_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dE2000</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HyperUnet   augmented noise   Adam</td>\n",
       "      <td>1.02±0.5</td>\n",
       "      <td>4.11±1.3</td>\n",
       "      <td>33.42±2.6</td>\n",
       "      <td>0.99±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HyperUnet   augmented noise   rmsprop</td>\n",
       "      <td>1.02±0.5</td>\n",
       "      <td>4.09±1.3</td>\n",
       "      <td>33.45±2.7</td>\n",
       "      <td>0.99±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HyperUnet   no augmented   Adam</td>\n",
       "      <td>1.01±0.5</td>\n",
       "      <td>4.01±1.3</td>\n",
       "      <td>33.62±2.7</td>\n",
       "      <td>0.99±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base model</td>\n",
       "      <td>1.76±0.8</td>\n",
       "      <td>10.35±3.7</td>\n",
       "      <td>25.42±3.0</td>\n",
       "      <td>0.97±0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model    dE2000        MAE       PSNR  \\\n",
       "0     HyperUnet   augmented noise   Adam  1.02±0.5   4.11±1.3  33.42±2.6   \n",
       "1  HyperUnet   augmented noise   rmsprop  1.02±0.5   4.09±1.3  33.45±2.7   \n",
       "2        HyperUnet   no augmented   Adam  1.01±0.5   4.01±1.3  33.62±2.7   \n",
       "3                             base model  1.76±0.8  10.35±3.7  25.42±3.0   \n",
       "\n",
       "       SSIM  \n",
       "0  0.99±0.0  \n",
       "1  0.99±0.0  \n",
       "2  0.99±0.0  \n",
       "3  0.97±0.0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics_df_mean_plus_std = metrics_df_mean.iloc[:, 1:].astype(str) + u\"\\u00B1\" + metrics_df_std.iloc[:, 1:].astype(str)\n",
    "metrics_df_mean_plus_std.insert(0, \"Model\", metrics_df_mean.iloc[:, 0])\n",
    "metrics_df_mean_plus_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_mean_plus_std.to_csv(\"metrics_df_mean_plus_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
