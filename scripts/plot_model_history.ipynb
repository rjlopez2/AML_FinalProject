{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch\n",
    "# !pip install --upgrade tensorflow\n",
    "# !pip install --upgrade jax\n",
    "# !pip install --upgrade keras-nlp\n",
    "# !pip install --upgrade keras-cv\n",
    "# !pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 11:41:01.194632: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import util\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from toloboy.toloboy import RGB2LAB, from_LAB_to_RGB_img\n",
    "from tqdm import tqdm\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "from skimage.color import deltaE_ciede2000\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions/classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom Dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwisstopoDataset:\n",
    "    def __init__(self, img_indx, transform=None, large_dataset=False, return_label=True, batch_size=32, shuffle=False):\n",
    "        self.img_indx = img_indx\n",
    "        self.transform = transform\n",
    "        self.large_dataset = large_dataset\n",
    "        self.return_label = return_label\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Set the appropriate port based on the dataset size\n",
    "        self.port = 1986 if self.large_dataset else 1985\n",
    "\n",
    "        # Load metadata\n",
    "        self.metadata_file = self._load_metadata()\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        raw_data_csv_file_link = f\"https://perritos.myasustor.com:{self.port}/metadata.csv\"\n",
    "        return pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "\n",
    "    def _fetch_image(self, img_id):\n",
    "        img_in_server_link = f\"https://perritos.myasustor.com:{self.port}/data/img_id_{img_id}.jpg\"\n",
    "        response = requests.get(img_in_server_link)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "\n",
    "    def _process_image(self, img_id):\n",
    "        image = self._fetch_image(img_id)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            image = image / 255.0  # Default normalization\n",
    "        return image\n",
    "\n",
    "    def _get_label(self, idx):\n",
    "        return self.metadata_file[\"class\"].iloc[idx]\n",
    "\n",
    "    def _generator(self):\n",
    "        if self.shuffle:\n",
    "            img_indices = np.random.permutation(len(self.img_indx))\n",
    "        else:\n",
    "            img_indices = self.img_indx\n",
    "\n",
    "        for idx in range(len(self.img_indx)):\n",
    "            image = self._process_image(self.img_indx[idx])\n",
    "            L, AB = image  # Unpack the transformed image\n",
    "            if self.return_label:\n",
    "                label = self._get_label(idx)\n",
    "                yield (L, AB), label\n",
    "            else:\n",
    "                yield L, AB\n",
    "\n",
    "    def get_dataset(self):\n",
    "        # Dynamically infer the shapes of L and AB channels\n",
    "        def _dynamic_output_signature():\n",
    "            example_image = self._fetch_image(self.img_indx[0])\n",
    "            example_transformed = self.transform(example_image)\n",
    "            L, AB = example_transformed\n",
    "            L_shape = tf.TensorSpec(shape=L.shape, dtype=tf.float32)\n",
    "            AB_shape = tf.TensorSpec(shape=AB.shape, dtype=tf.float32)\n",
    "            if self.return_label:\n",
    "                return ((L_shape, AB_shape), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
    "            else:\n",
    "                return (L_shape, AB_shape)\n",
    "\n",
    "        output_signature = _dynamic_output_signature()\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self._generator, output_signature=output_signature)\n",
    "        dataset = dataset.batch(self.batch_size, drop_remainder=True) # use drop reminder to have same size always\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LTransformation(object):\n",
    "    def __init__(self, contrast_range=(0.9, 1), brightness_range=(-0.05, 0.20), noise_var_range=(0, 0.005)):\n",
    "        self.contrast_range = contrast_range\n",
    "        self.brightness_range = brightness_range\n",
    "        self.noise_var_range = noise_var_range\n",
    "\n",
    "    def _apply_factor(self, L_channel, contrast_factor, brightness_factor):\n",
    "        # Apply adjusted brightness and contrast to the L channel\n",
    "        L_adjusted = contrast_factor * L_channel + brightness_factor\n",
    "\n",
    "        # Clip adjusted L channel to [0, 1]\n",
    "        L_adjusted = np.clip(L_adjusted, 0, 1)\n",
    "\n",
    "        return L_adjusted\n",
    "\n",
    "    def _apply_noise(self, L_channel, noise_var):\n",
    "        # Apply Gaussian noise to the L channel\n",
    "        L_noisy = util.random_noise(L_channel, mode='gaussian', var=noise_var)\n",
    "\n",
    "        # Clip noisy L channel to [0, 1]\n",
    "        L_noisy = np.clip(L_noisy, 0, 1)\n",
    "\n",
    "        return L_noisy\n",
    "\n",
    "    def _randomize_factors(self):\n",
    "        return np.random.uniform(*self.brightness_range), np.random.uniform(*self.contrast_range)\n",
    "\n",
    "    def _randomize_noise_var(self):\n",
    "        return np.random.uniform(*self.noise_var_range)\n",
    "\n",
    "    def __call__(self, L_channel):\n",
    "        while True:\n",
    "            brightness_factor, contrast_factor = self._randomize_factors()\n",
    "            noise_var = self._randomize_noise_var()\n",
    "\n",
    "            # Apply adjusted brightness and contrast to the L channel\n",
    "            L_adjusted = self._apply_factor(L_channel, contrast_factor, brightness_factor)\n",
    "\n",
    "            # Apply Gaussian noise to the L channel\n",
    "            L_augmented = self._apply_noise(L_adjusted, noise_var)\n",
    "\n",
    "            # Check if values are within range\n",
    "            if 0 <= np.min(L_augmented) <= np.max(L_augmented) <= 1:\n",
    "                break\n",
    "\n",
    "        return L_augmented, contrast_factor, brightness_factor, noise_var\n",
    "\n",
    "def convert_RGB_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB(R1, G1, B1)\n",
    "\n",
    "    train_input[:, :, 0] = L.reshape((sz_x, sz_y))\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs\n",
    "\n",
    "\n",
    "def convert_RGB__and_augment_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB(R1, G1, B1)\n",
    "\n",
    "    # Apply LTransformation to the L channel\n",
    "    L_transformation = LTransformation()\n",
    "    L_augmented, _, _, _ = L_transformation(L.reshape((sz_x, sz_y)))\n",
    "\n",
    "    train_input[:, :, 0] = L_augmented\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_transform(image):\n",
    "    L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_and_augment_transform(image):\n",
    "    if np.random.rand() < 0.25:  # only apply augmentation to 25% of the data\n",
    "        L, AB = convert_RGB__and_augment_to_feed_model(image)\n",
    "    else:\n",
    "        L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check info from the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was initially created using the scripts `retrieve_data.ipynb` and stored in a private server for later (re)use.\n",
    "In the metadata.csv file we get the information on original link, class and coordinates of each image.\n",
    "\n",
    "NOTE: the following are links stored in a private server, jet they are still publically available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10008 entries, 0 to 10007\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   img_id      10008 non-null  int64  \n",
      " 1   img_name    10008 non-null  object \n",
      " 2   latitude    10008 non-null  float64\n",
      " 3   longitude   10008 non-null  float64\n",
      " 4   zoom_level  10008 non-null  int64  \n",
      " 5   class       10008 non-null  int64  \n",
      " 6   link        10008 non-null  object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 625.5+ KB\n"
     ]
    }
   ],
   "source": [
    "is_large_dataset = True\n",
    "\n",
    "if is_large_dataset:\n",
    "    server_port = 1986 # Large dataset of ~10K images\n",
    "else:\n",
    "    server_port = 1985 # Large dataset of ~10K images\n",
    "# server_port = 1985 # initial dataset of 3.6K images\n",
    "\n",
    "raw_data_csv_file_link = f\"https://perritos.myasustor.com:{server_port}/metadata.csv\"\n",
    "\n",
    "\n",
    "metadata_raw_df = pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "metadata_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Train, Valid and Test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the column `image_id` from the metadata as index of the images and then we perform standard shufling and splitting.\n",
    "\n",
    "The final ratio for the train, validation and test dastasets are: 70, 29 and 1 % respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size fo the train dataset is: 7005.\n",
      "the size fo the validation dataset is: 2902.\n",
      "the size fo the test dataset is: 101.\n"
     ]
    }
   ],
   "source": [
    "dataX, dataY = metadata_raw_df[\"img_id\"].to_list(), metadata_raw_df[\"class\"] .to_list()\n",
    "\n",
    "rand_state = 9898\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.29\n",
    "test_ratio = 0.01\n",
    "\n",
    "\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio, stratify = dataY, random_state=rand_state)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test, random_state=rand_state)\n",
    "\n",
    "print(f\"the size fo the train dataset is: {len(x_train)}.\\nthe size fo the validation dataset is: {len(x_val)}.\\nthe size fo the test dataset is: {len(x_test)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 1\n",
    "\n",
    "# Instantiate the dataset\n",
    "# img_indices = [0, 1, 2, 3, 4, 5]  # Example indices\n",
    "\n",
    "\n",
    "\n",
    "test_dataset_loader = SwisstopoDataset(x_test,\n",
    "                           transform=convert_to_LAB_transform,\n",
    "                           large_dataset=True,\n",
    "                           return_label=True,\n",
    "                           batch_size=b_size,\n",
    "                           shuffle=False)\n",
    "\n",
    "# train_dataset = train_dataset_loader.get_dataset()\n",
    "test_dataset = test_dataset_loader.get_dataset()\n",
    "# valid_dataset = valid_dataset_loader.get_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tf.data.Dataset\n",
    "# Iterate over the dataset\n",
    "# for batch in test_dataset:\n",
    "#     # (L_channel, AB_channels), labels = batch # print with labels\n",
    "#     # print(L_channel.shape, AB_channels.shape, print(labels.shape))\n",
    "#     L_channel, AB_channels= batch # print without labels\n",
    "#     print(L_channel.shape, AB_channels.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
